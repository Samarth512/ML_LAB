{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPx4ZtzrGkRpYczMQcjWa8k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"Bi7MSKse71mP","executionInfo":{"status":"ok","timestamp":1741761144869,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sagar Irappa Bangari","userId":"05177450473290962210"}}},"outputs":[],"source":["\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Sample weather dataset\n","data = {\n","    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n","    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n","    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n","    'Windy': ['No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n","    'Play Tennis?': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n","}\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","\n","# Function to calculate entropy\n","def entropy(target):\n","    # Get the counts of each class\n","    class_counts = target.value_counts()\n","    # Calculate the entropy using the formula\n","    probabilities = class_counts / len(target)\n","    return -np.sum(probabilities * np.log2(probabilities))\n","\n","# Function to calculate information gain\n","def information_gain(data, feature, target):\n","    # Calculate the entropy of the whole dataset\n","    entropy_before = entropy(target)\n","\n","    # Get the unique values of the feature\n","    feature_values = data[feature].unique()\n","\n","    # Calculate the weighted entropy after the split\n","    weighted_entropy = 0\n","    for value in feature_values:\n","        subset = target[data[feature] == value]\n","        weighted_entropy += (len(subset) / len(target)) * entropy(subset)\n","\n","    # Information gain is the reduction in entropy\n","    return entropy_before - weighted_entropy\n","\n","# Function to print entropy and information gain for each feature\n","def print_entropy_and_gain(data, features, target):\n","    print(\"\\nEntropy and Information Gain for each feature:\")\n","    for feature in features:\n","        gain = information_gain(data, feature, target)\n","        ent = entropy(target)\n","        print(f\"Feature: {feature} | Entropy: {ent:.4f} | Information Gain: {gain:.4f}\")\n","\n","# Function to build the decision tree recursively\n","def build_tree(data, target, features):\n","    # Base case: If all target values are the same, return a leaf node\n","    if len(target.unique()) == 1:\n","        return target.iloc[0]\n","\n","    # Base case: If no features left to split, return the majority class\n","    if len(features) == 0:\n","        return target.mode()[0]\n","\n","    # Calculate information gain for each feature\n","    gains = {feature: information_gain(data, feature, target) for feature in features}\n","\n","    # Find the feature with the highest information gain\n","    best_feature = max(gains, key=gains.get)\n","\n","    # Create the tree node with the best feature\n","    tree = {best_feature: {}}\n","\n","    # Get the unique values of the best feature\n","    feature_values = data[best_feature].unique()\n","\n","    # Recursively build the tree for each subset of the data\n","    for value in feature_values:\n","        subset_data = data[data[best_feature] == value]\n","        subset_target = target[data[best_feature] == value]\n","\n","        # Remove the best feature from the list of features for the next level\n","        remaining_features = [f for f in features if f != best_feature]\n","\n","        # Build the subtree for the subset\n","        subtree = build_tree(subset_data, subset_target, remaining_features)\n","\n","        # Add the subtree to the tree\n","        tree[best_feature][value] = subtree\n","\n","    return tree\n","\n","# Function to print the tree in a visually structured way\n","def print_tree(tree, indent=\"\"):\n","    if isinstance(tree, dict):\n","        for feature, branches in tree.items():\n","            print(f\"{indent}{feature}:\")\n","            for value, subtree in branches.items():\n","                print(f\"{indent}  {value} ->\", end=\" \")\n","                print_tree(subtree, indent + \"    \")\n","    else:\n","        print(f\"{indent}{tree}\")\n","\n","# Target variable\n","target = df['Play Tennis?']\n","\n","# Features\n","features = ['Outlook', 'Temperature', 'Humidity', 'Windy']\n","\n","# Step 1: Print entropy and information gain for each feature\n","print_entropy_and_gain(df, features, target)\n","\n","# Step 2: Build the decision tree\n","tree = build_tree(df, target, features)\n","\n","# Step 3: Print the decision tree (formatted)\n","print(\"\\nDecision Tree:\")\n","print_tree(tree, indent=\"    \")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPYlvjWoA5p4","executionInfo":{"status":"ok","timestamp":1741761505522,"user_tz":-330,"elapsed":70,"user":{"displayName":"Sagar Irappa Bangari","userId":"05177450473290962210"}},"outputId":"ad99b93e-04b9-4d2c-f358-6c5a9210c335"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Entropy and Information Gain for each feature:\n","Feature: Outlook | Entropy: 0.9403 | Information Gain: 0.2467\n","Feature: Temperature | Entropy: 0.9403 | Information Gain: 0.0292\n","Feature: Humidity | Entropy: 0.9403 | Information Gain: 0.1518\n","Feature: Windy | Entropy: 0.9403 | Information Gain: 0.0481\n","\n","Decision Tree:\n","    Outlook:\n","      Sunny ->         Humidity:\n","          High ->             No\n","          Normal ->             Yes\n","      Overcast ->         Yes\n","      Rain ->         Windy:\n","          No ->             Yes\n","          Yes ->             No\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from graphviz import Digraph\n","\n","# Sample weather dataset\n","data = {\n","    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n","    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n","    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n","    'Windy': ['No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n","    'Play Tennis?': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n","}\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","\n","# Function to calculate entropy\n","def entropy(target):\n","    class_counts = target.value_counts()\n","    probabilities = class_counts / len(target)\n","    return -np.sum(probabilities * np.log2(probabilities))\n","\n","# Function to calculate information gain\n","def information_gain(data, feature, target):\n","    entropy_before = entropy(target)\n","    feature_values = data[feature].unique()\n","    weighted_entropy = 0\n","    for value in feature_values:\n","        subset = target[data[feature] == value]\n","        weighted_entropy += (len(subset) / len(target)) * entropy(subset)\n","    return entropy_before - weighted_entropy\n","\n","# Function to build the decision tree recursively\n","def build_tree(data, target, features):\n","    if len(target.unique()) == 1:\n","        return target.iloc[0]\n","    if len(features) == 0:\n","        return target.mode()[0]\n","\n","    gains = {feature: information_gain(data, feature, target) for feature in features}\n","    best_feature = max(gains, key=gains.get)\n","\n","    tree = {best_feature: {}}\n","    feature_values = data[best_feature].unique()\n","\n","    for value in feature_values:\n","        subset_data = data[data[best_feature] == value]\n","        subset_target = target[data[best_feature] == value]\n","        remaining_features = [f for f in features if f != best_feature]\n","        subtree = build_tree(subset_data, subset_target, remaining_features)\n","        tree[best_feature][value] = subtree\n","\n","    return tree\n","\n","# Function to visualize the tree using Graphviz\n","def visualize_tree(tree, dot=None, parent=None, edge_label=''):\n","    if dot is None:\n","        dot = Digraph()\n","\n","    if isinstance(tree, dict):\n","        for feature, branches in tree.items():\n","            node_id = str(id(branches))  # Unique node identifier\n","            dot.node(node_id, feature)\n","\n","            if parent:\n","                dot.edge(parent, node_id, label=edge_label)\n","\n","            for value, subtree in branches.items():\n","                value_node_id = str(id(value))  # Unique identifier for the value node\n","                dot.node(value_node_id, str(value), shape='ellipse')\n","                dot.edge(node_id, value_node_id, label=str(value))\n","                visualize_tree(subtree, dot, value_node_id, str(value))\n","    else:\n","        dot.node(str(id(tree)), str(tree), shape='ellipse', color='lightblue')\n","        dot.edge(parent, str(id(tree)), label=edge_label)\n","\n","    return dot\n","\n","# Target variable\n","target = df['Play Tennis?']\n","\n","# Features\n","features = ['Outlook', 'Temperature', 'Humidity', 'Windy']\n","\n","# Build the decision tree\n","tree = build_tree(df, target, features)\n","\n","# Visualize the decision tree\n","dot = visualize_tree(tree)\n","\n","# Render the tree to a file and display it\n","dot.render('decision_tree', format='png', cleanup=True)\n","\n","# If you want to display the tree in Jupyter Notebook, you can use:\n","# from IPython.display import Image\n","# Image(filename='decision_tree.png')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Tof3sWi6EDsg","executionInfo":{"status":"ok","timestamp":1741761772692,"user_tz":-330,"elapsed":56,"user":{"displayName":"Sagar Irappa Bangari","userId":"05177450473290962210"}},"outputId":"3ffd9378-1215-4278-bd9d-1333d711db74"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'decision_tree.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]}]}